{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ee3466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b3c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/dataset-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f1a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(df):\n",
    "\n",
    "    unique_ids = pd.unique(df[['id_start', 'id_end']].values.ravel('K'))\n",
    "    distance_matrix = pd.DataFrame(np.inf, index=unique_ids, columns=unique_ids)\n",
    "    np.fill_diagonal(distance_matrix.values, 0)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        distance_matrix.loc[row['id_start'], row['id_end']] = row['distance']\n",
    "        distance_matrix.loc[row['id_end'], row['id_start']] = row['distance']\n",
    "\n",
    "    for k in unique_ids:\n",
    "        for i in unique_ids:\n",
    "            for j in unique_ids:\n",
    "                if distance_matrix.loc[i, k] + distance_matrix.loc[k, j] < distance_matrix.loc[i, j]:\n",
    "                    distance_matrix.loc[i, j] = distance_matrix.loc[i, k] + distance_matrix.loc[k, j]\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cd5cce",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12508\\605512062.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalculate_distance_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12508\\3281560342.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                     \u001b[0mdistance_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   4210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4211\u001b[0m             \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4212\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4214\u001b[1;33m         \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4215\u001b[0m         \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   4640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4641\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4643\u001b[0m             \u001b[1;31m# for a chain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4644\u001b[1;33m             \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4645\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6311\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6312\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6313\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6314\u001b[1;33m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6315\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6317\u001b[0m         \u001b[1;31m# if this fails, go on to more involved attribute setting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "calculate_distance_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_distance_matrix(df):\n",
    "    distance_matrix = calculate_distance_matrix(df)\n",
    "    unrolled_df = distance_matrix.reset_index().melt(id_vars='index', \n",
    "                                                       var_name='id_end', \n",
    "                                                       value_name='distance')\n",
    "    \n",
    "    unrolled_df = unrolled_df.rename(columns={'index': 'id_start'})\n",
    "    \n",
    "    unrolled_df = unrolled_df[unrolled_df['id_start'] != unrolled_df['id_end']]\n",
    "    unrolled_df = unrolled_df[unrolled_df['distance'] != float('inf')]\n",
    "    \n",
    "    return unrolled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a8787",
   "metadata": {},
   "outputs": [],
   "source": [
    "unroll_distance_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b548535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ids_within_ten_percentage_threshold(df, reference_id)->pd.DataFrame():\n",
    "    \"\"\"\n",
    "    Find all IDs whose average distance lies within 10% of the average distance of the reference ID.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame)\n",
    "        reference_id (int)\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with IDs whose average distance is within the specified percentage threshold\n",
    "                          of the reference ID's average distance.\n",
    "    \"\"\"\n",
    "    # Write your logic here\n",
    "\n",
    "    ref_distances = df[df['id_start'] == reference_id]\n",
    "\n",
    "    # Calculate the average distance for the reference_id\n",
    "    if ref_distances.empty:\n",
    "        return []  # Return empty if no distances found for the reference ID\n",
    "\n",
    "    average_distance = ref_distances['distance'].mean()\n",
    "\n",
    "    # Calculate the threshold values (10% above and below the average distance)\n",
    "    lower_bound = average_distance * 0.9\n",
    "    upper_bound = average_distance * 1.1\n",
    "\n",
    "    # Find IDs within the threshold\n",
    "    within_threshold = df[\n",
    "        (df['id_start'] != reference_id) &  # Exclude the reference ID itself\n",
    "        (df['distance'] >= lower_bound) &\n",
    "        (df['distance'] <= upper_bound)\n",
    "        ]\n",
    "\n",
    "    # Get the unique id_start values within the threshold and sort them\n",
    "    result_ids = sorted(within_threshold['id_start'].unique())\n",
    "\n",
    "    return result_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b52362",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_ids_within_ten_percentage_threshold(df, 1001406)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_toll_rate(unrolled_df):\n",
    "    # Define the rate coefficients for each vehicle type\n",
    "    rate_coefficients = {\n",
    "        'moto': 0.8,\n",
    "        'car': 1.2,\n",
    "        'rv': 1.5,\n",
    "        'bus': 2.2,\n",
    "        'truck': 3.6\n",
    "    }\n",
    "    \n",
    "    # Calculate toll rates for each vehicle type\n",
    "    for vehicle, coefficient in rate_coefficients.items():\n",
    "        unrolled_df[vehicle] = unrolled_df['distance'] * coefficient\n",
    "    \n",
    "    return unrolled_df.drop(['distance'], axis=1)\n",
    "\n",
    "# Example usage:\n",
    "unrolled_df = unroll_distance_matrix(df)\n",
    "toll_rates_df = calculate_toll_rate(unrolled_df)\n",
    "print(toll_rates_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import time, timedelta\n",
    "\n",
    "def calculate_time_based_toll_rates(unrolled_df):\n",
    "    # Define days of the week\n",
    "    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    \n",
    "    # Define time intervals and discount factors\n",
    "    time_intervals = [\n",
    "        (time(0, 0), time(10, 0), 0.8),    # Weekdays morning discount\n",
    "        (time(10, 0), time(18, 0), 1.2),   # Weekdays day rate\n",
    "        (time(18, 0), time(23, 59, 59), 0.8)  # Weekdays evening discount\n",
    "    ]\n",
    "    weekend_discount = 0.7  # Constant for weekends\n",
    "\n",
    "    # Prepare a list to hold the new rows\n",
    "    new_rows = []\n",
    "\n",
    "    # Iterate through each unique id_start and id_end pair\n",
    "    for (id_start, id_end), group in unrolled_df.groupby(['id_start', 'id_end']):\n",
    "        for day in days_of_week:\n",
    "            for start_time, end_time, factor in time_intervals:\n",
    "                # Add weekday entries\n",
    "                new_rows.append({\n",
    "                    'id_start': id_start,\n",
    "                    'id_end': id_end,\n",
    "                    'start_day': day,\n",
    "                    'start_time': start_time,\n",
    "                    'end_day': day,\n",
    "                    'end_time': end_time,\n",
    "                    'moto': group['moto'].values[0] * factor,\n",
    "                    'car': group['car'].values[0] * factor,\n",
    "                    'rv': group['rv'].values[0] * factor,\n",
    "                    'bus': group['bus'].values[0] * factor,\n",
    "                    'truck': group['truck'].values[0] * factor\n",
    "                })\n",
    "        \n",
    "        # Add weekend entries\n",
    "        for day in ['Saturday', 'Sunday']:\n",
    "            new_rows.append({\n",
    "                'id_start': id_start,\n",
    "                'id_end': id_end,\n",
    "                'start_day': day,\n",
    "                'start_time': time(0, 0),\n",
    "                'end_day': day,\n",
    "                'end_time': time(23, 59, 59),\n",
    "                'moto': group['moto'].values[0] * weekend_discount,\n",
    "                'car': group['car'].values[0] * weekend_discount,\n",
    "                'rv': group['rv'].values[0] * weekend_discount,\n",
    "                'bus': group['bus'].values[0] * weekend_discount,\n",
    "                'truck': group['truck'].values[0] * weekend_discount\n",
    "            })\n",
    "\n",
    "    # Create a new DataFrame from the new rows\n",
    "    time_based_toll_df = pd.DataFrame(new_rows)\n",
    "    \n",
    "    return time_based_toll_df\n",
    "\n",
    "# Example usage:\n",
    "unrolled_df = unroll_distance_matrix(df)\n",
    "toll_rates_time_based_df = calculate_toll_rate(unrolled_df)\n",
    "toll_rates_time_based_df = calculate_time_based_toll_rates(toll_rates_df)\n",
    "print(toll_rates_time_based_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import time\n",
    "\n",
    "def calculate_time_based_toll_rates(unrolled_df):\n",
    "    # Define days of the week\n",
    "    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    \n",
    "    # Define time intervals and discount factors\n",
    "    time_intervals = [\n",
    "        (time(0, 0), time(10, 0), 0.8),    # Weekdays morning discount\n",
    "        (time(10, 0), time(18, 0), 1.2),   # Weekdays day rate\n",
    "        (time(18, 0), time(23, 59, 59), 0.8)  # Weekdays evening discount\n",
    "    ]\n",
    "    weekend_discount = 0.7  # Constant for weekends\n",
    "\n",
    "    # Prepare a list to hold the new rows\n",
    "    new_rows = []\n",
    "\n",
    "    # Iterate through each unique id_start and id_end pair\n",
    "    for (id_start, id_end), group in unrolled_df.groupby(['id_start', 'id_end']):\n",
    "        # Extract the distance and toll rates from the group\n",
    "        distance = group['distance'].values[0]  # Assuming distance is the same for the pair\n",
    "        moto_rate = group['moto'].values[0]\n",
    "        car_rate = group['car'].values[0]\n",
    "        rv_rate = group['rv'].values[0]\n",
    "        bus_rate = group['bus'].values[0]\n",
    "        truck_rate = group['truck'].values[0]\n",
    "\n",
    "        # Add weekday entries\n",
    "        for day in days_of_week:\n",
    "            for start_time, end_time, factor in time_intervals:\n",
    "                new_rows.append({\n",
    "                    'id_start': id_start,\n",
    "                    'id_end': id_end,\n",
    "                    'distance': distance,\n",
    "                    'start_day': day,\n",
    "                    'start_time': start_time,\n",
    "                    'end_day': day,\n",
    "                    'end_time': end_time,\n",
    "                    'moto': moto_rate * factor,\n",
    "                    'car': car_rate * factor,\n",
    "                    'rv': rv_rate * factor,\n",
    "                    'bus': bus_rate * factor,\n",
    "                    'truck': truck_rate * factor\n",
    "                })\n",
    "        \n",
    "        # Add weekend entries\n",
    "        for day in ['Saturday', 'Sunday']:\n",
    "            new_rows.append({\n",
    "                'id_start': id_start,\n",
    "                'id_end': id_end,\n",
    "                'distance': distance,\n",
    "                'start_day': day,\n",
    "                'start_time': time(0, 0),\n",
    "                'end_day': day,\n",
    "                'end_time': time(23, 59, 59),\n",
    "                'moto': moto_rate * weekend_discount,\n",
    "                'car': car_rate * weekend_discount,\n",
    "                'rv': rv_rate * weekend_discount,\n",
    "                'bus': bus_rate * weekend_discount,\n",
    "                'truck': truck_rate * weekend_discount\n",
    "            })\n",
    "\n",
    "    # Create a new DataFrame from the new rows\n",
    "    time_based_toll_df = pd.DataFrame(new_rows)\n",
    "    \n",
    "    return time_based_toll_df\n",
    "\n",
    "unrolled_df = unroll_distance_matrix(df)\n",
    "toll_rates_time_based_df = calculate_toll_rate(unrolled_df)\n",
    "toll_rates_time_based_df = calculate_time_based_toll_rates(toll_rates_df)\n",
    "print(toll_rates_time_based_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import time\n",
    "\n",
    "def calculate_time_based_toll_rates(unrolled_df):\n",
    "    # Define days of the week\n",
    "    days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    \n",
    "    # Define time intervals and discount factors\n",
    "    time_intervals = [\n",
    "        (time(0, 0), time(10, 0), 0.8),    # Weekdays morning discount\n",
    "        (time(10, 0), time(18, 0), 1.2),   # Weekdays day rate\n",
    "        (time(18, 0), time(23, 59, 59), 0.8)  # Weekdays evening discount\n",
    "    ]\n",
    "    weekend_discount = 0.7  # Constant for weekends\n",
    "\n",
    "    # Prepare a list to hold the new rows\n",
    "    new_rows = []\n",
    "\n",
    "    # Iterate through each unique id_start and id_end pair\n",
    "    for (id_start, id_end), group in unrolled_df.groupby(['id_start', 'id_end']):\n",
    "        # Extract the distance and toll rates from the group\n",
    "        distance = group['distance'].values[0]  # Assuming distance is the same for the pair\n",
    "        moto_rate = group['moto'].values[0]\n",
    "        car_rate = group['car'].values[0]\n",
    "        rv_rate = group['rv'].values[0]\n",
    "        bus_rate = group['bus'].values[0]\n",
    "        truck_rate = group['truck'].values[0]\n",
    "\n",
    "        # Add weekday entries\n",
    "        i=0\n",
    "        for day in days_of_week:\n",
    "            for start_time, end_time, factor in time_intervals:\n",
    "                new_rows.append({\n",
    "                    'id_start': id_start,\n",
    "                    'id_end': id_end,\n",
    "                    'distance': distance,\n",
    "                    'start_day': days_of_week,\n",
    "                    'start_time': start_time,\n",
    "                    'end_day': day,\n",
    "                    'end_time': end_time,\n",
    "                    'moto': moto_rate * factor,\n",
    "                    'car': car_rate * factor,\n",
    "                    'rv': rv_rate * factor,\n",
    "                    'bus': bus_rate * factor,\n",
    "                    'truck': truck_rate * factor\n",
    "                })\n",
    "        \n",
    "        # Add weekend entries\n",
    "        for day in ['Saturday', 'Sunday']:\n",
    "            new_rows.append({\n",
    "                'id_start': id_start,\n",
    "                'id_end': id_end,\n",
    "                'distance': distance,\n",
    "                'start_day': day,\n",
    "                'start_time': time(0, 0),\n",
    "                'end_day': day,\n",
    "                'end_time': time(23, 59, 59),\n",
    "                'moto': moto_rate * weekend_discount,\n",
    "                'car': car_rate * weekend_discount,\n",
    "                'rv': rv_rate * weekend_discount,\n",
    "                'bus': bus_rate * weekend_discount,\n",
    "                'truck': truck_rate * weekend_discount\n",
    "            })\n",
    "\n",
    "    # Create a new DataFrame from the new rows\n",
    "    time_based_toll_df = pd.DataFrame(new_rows)\n",
    "    \n",
    "    return time_based_toll_df\n",
    "\n",
    "unrolled_df = unroll_distance_matrix(df)\n",
    "toll_rates_time_based_df = calculate_toll_rate(unrolled_df)\n",
    "toll_rates_time_based_df = calculate_time_based_toll_rates(toll_rates_df)\n",
    "print(toll_rates_time_based_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3052684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_time_completeness(df):\n",
    "    # Create a multi-index for the output\n",
    "    index = pd.MultiIndex.from_frame(df[['id', 'id_2']].drop_duplicates())\n",
    "    \n",
    "    # Prepare a Series to hold the results\n",
    "    results = pd.Series(False, index=index)\n",
    "\n",
    "    # Iterate through each unique (id, id_2) pair\n",
    "    for (id_val, id_2_val), group in df.groupby(['id', 'id_2']):\n",
    "        # Initialize sets for days and time coverage\n",
    "        days_covered = set()\n",
    "        time_ranges = []\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            # Collect days\n",
    "            days_covered.add(row['startDay'])\n",
    "            days_covered.add(row['endDay'])\n",
    "            \n",
    "            # Collect time ranges as tuples\n",
    "            time_ranges.append((row['startTime'], row['endTime'], row['startDay'], row['endDay']))\n",
    "\n",
    "        # Check if all days are covered\n",
    "        all_days = {'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'}\n",
    "        is_days_covered = days_covered >= all_days\n",
    "        \n",
    "        # Check if the time ranges cover a full 24-hour period\n",
    "        is_full_24_hours = False\n",
    "        \n",
    "        # Normalize time strings to seconds for comparison\n",
    "        time_slots = []\n",
    "        for start_time, end_time, start_day, end_day in time_ranges:\n",
    "            start_seconds = int(start_time.split(':')[0]) * 3600 + int(start_time.split(':')[1]) * 60 + int(start_time.split(':')[2])\n",
    "            end_seconds = int(end_time.split(':')[0]) * 3600 + int(end_time.split(':')[1]) * 60 + int(end_time.split(':')[2])\n",
    "            time_slots.append((start_seconds, end_seconds))\n",
    "\n",
    "        # Check for 24-hour coverage\n",
    "        # Here, we can consider all time slots in a single day\n",
    "        total_time_covered = [0] * 86400  # seconds in a day\n",
    "\n",
    "        for start_seconds, end_seconds in time_slots:\n",
    "            if start_seconds < end_seconds:\n",
    "                for sec in range(start_seconds, end_seconds):\n",
    "                    total_time_covered[sec] = 1\n",
    "            else:  # Handle overnight spans (e.g., 23:00 to 01:00)\n",
    "                for sec in range(start_seconds, 86400):\n",
    "                    total_time_covered[sec] = 1\n",
    "                for sec in range(0, end_seconds):\n",
    "                    total_time_covered[sec] = 1\n",
    "        \n",
    "        # If all 86400 seconds are covered\n",
    "        is_full_24_hours = all(total_time_covered)\n",
    "\n",
    "        # Store the result for the current (id, id_2) pair\n",
    "        results[(id_val, id_2_val)] = not (is_days_covered and is_full_24_hours)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "df = pd.read_csv('datasets/dataset-1.csv')\n",
    "result_series = check_time_completeness(df)\n",
    "print(result_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7541ddca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polyline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolyline\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolyline_to_dataframe\u001b[39m(polyline_str: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Converts a polyline string into a DataFrame with latitude, longitude, and distance between consecutive points.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m        pd.DataFrame: A DataFrame containing latitude, longitude, and distance in meters.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'polyline'"
     ]
    }
   ],
   "source": [
    "import polyline\n",
    "def polyline_to_dataframe(polyline_str: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a polyline string into a DataFrame with latitude, longitude, and distance between consecutive points.\n",
    "    \n",
    "    Args:\n",
    "        polyline_str (str): The encoded polyline string.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing latitude, longitude, and distance in meters.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'polyline': [polyline_str]})\n",
    "\n",
    "    # Decode the polyline and extract latitude and longitude\n",
    "    df['lat/long'] = df['polyline'].map(lambda x: polyline.decode(x))\n",
    "\n",
    "    # Expand lat/long into separate columns\n",
    "    df[['lat', 'long']] = pd.DataFrame(df['lat/long'].tolist(), index=df.index)\n",
    "\n",
    "    # Calculate distances using the Haversine formula directly\n",
    "    distances = [0.0]  # First distance is 0\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        lat1, lon1 = df.iloc[i - 1][['lat', 'long']]\n",
    "        lat2, lon2 = df.iloc[i][['lat', 'long']]\n",
    "\n",
    "        # Haversine calculation directly in the loop\n",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        r = 6371000  # Earth radius in meters\n",
    "        distance = c * r\n",
    "\n",
    "        distances.append(distance)\n",
    "\n",
    "    df['distance'] = distances\n",
    "\n",
    "    return df[['lat', 'long', 'distance']]\n",
    "print(polyline_to_dataframe('onl~Fj|cvOrsEg}@rHuvK'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fb05b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polyline in c:\\users\\pravin\\miniconda3\\lib\\site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install polyline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ebe9d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polyline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolyline\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'polyline'"
     ]
    }
   ],
   "source": [
    "import polyline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e94988e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polyline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpolyline\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(polyline\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'polyline'"
     ]
    }
   ],
   "source": [
    "import polyline\n",
    "print(polyline.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe0a350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall polyline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8676375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polyline in c:\\users\\pravin\\miniconda3\\lib\\site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install polyline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94747ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
